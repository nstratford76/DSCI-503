{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b07cbb-a11d-44c5-a67f-ba8757510fe9",
   "metadata": {},
   "source": [
    "# DSCI 503 - Homework 04\n",
    "### Nathan Stratford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef90fe78-d3c1-4d46-a84b-9e17d1d14b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0eb9f4-ee52-4136-8eec-594bb9ac1b02",
   "metadata": {},
   "source": [
    "## Problem 1: Sample Mean and Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9058b14f-9a62-4bcf-9c61-8da7ca5606b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean:     16.60\n",
      "Sample Variance: 25.60\n"
     ]
    }
   ],
   "source": [
    "x = [10, 16, 26, 12, 17, 22, 14, 12, 21, 16 ]\n",
    "n = len(x)\n",
    "mean = np.sum(x) / n\n",
    "diff = [item - mean for item in x]\n",
    "squared_diff = [d**2 for d in diff]\n",
    "sample_variance = np.sum(squared_diff) / (n - 1)\n",
    "print(f\"Sample Mean:     {mean:.2f}\")\n",
    "print(f\"Sample Variance: {sample_variance:.2f}\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4d9d6b-0bcf-49d3-89cd-20c43324e853",
   "metadata": {},
   "source": [
    "## Problem 2: Scoring a Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2dc351-cd88-4dc9-8c5d-d3cf815063eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sse(true_y, pred_y):\n",
    "    true_np_array = np.array(true_y)\n",
    "    pred_np_array = np.array(pred_y)\n",
    "    result_array = true_np_array - pred_np_array\n",
    "    return np.sum(result_array ** 2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c40ad3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 SSE: 22.66\n",
      "Model 2 SSE: 19.90\n"
     ]
    }
   ],
   "source": [
    "true_y = [22.1, 17.9, 16.5, 14.3, 19.8, 23.7, 22.0, 18.4, 25.7, 19.2]\n",
    "pred_1 = [21.4, 16.7, 17.9, 12.1, 22.1, 25.1, 21.7, 19.3, 23.4, 19.9]\n",
    "pred_2 = [20.7, 18.1, 16.9, 13.6, 21.9, 24.8, 20.3, 21.1, 24.8, 18.4]\n",
    "print(f\"Model 1 SSE: {find_sse(true_y, pred_1):.2f}\")\n",
    "print(f\"Model 2 SSE: {find_sse(true_y, pred_2):.2f}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecd15f5",
   "metadata": {},
   "source": [
    "## Problem 3: Scoring a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2dae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(true_y, pred_y):\n",
    "    np_true_y = np.array(true_y)\n",
    "    np_pred_y = np.array(pred_y)\n",
    "    return np.sum(np.equal(np_true_y, np_pred_y)) / len(true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "621c5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "true_diag = ['P', 'P', 'N', 'N', 'P', 'N', 'N', 'N', 'P', 'N', 'N', 'N', 'N', 'P', 'P', 'N', 'N',\n",
    "'N', 'N', 'N']\n",
    "pred_diag = ['N', 'P', 'N', 'P', 'P', 'N', 'P', 'N', 'P', 'N', 'N', 'N', 'P', 'P', 'P', 'N', 'N',\n",
    "'N', 'P', 'N']\n",
    "print(\"Model Accuracy: \" + str(find_accuracy(true_diag, pred_diag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f52e9c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "true_labels = ['dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat',\n",
    " 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat']\n",
    "pred_labels = ['dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat',\n",
    " 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'dog', 'cat', 'dog', 'dog', 'cat', 'cat']\n",
    "print(\"Model Accuracy: \" + str(find_accuracy(true_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1e5f1a",
   "metadata": {},
   "source": [
    "## Problem 4: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f409d733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(true_y, pred_y):\n",
    "    np_true_y = np.array(true_y)\n",
    "    np_pred_y = np.array(pred_y)\n",
    "    classes = np.unique(true_y)\n",
    "    negative_class = classes[0]\n",
    "    positive_class = classes[1]\n",
    "    \n",
    "    accuracy = find_accuracy(true_y, pred_y)\n",
    "    TP = np.sum((np_true_y == positive_class) & (np_pred_y == positive_class))\n",
    "    FP = np.sum((np_true_y == negative_class) & (np_pred_y == positive_class))\n",
    "    TN = np.sum((np_true_y == negative_class) & (np_pred_y == negative_class))\n",
    "    FN = np.sum((np_true_y == positive_class) & (np_pred_y == negative_class))\n",
    "\n",
    "    positive_precision = TP / (TP + FP)\n",
    "    positive_recall = TP / (TP + FN) \n",
    "    negative_precision = TN / (TN + FN)\n",
    "    negative_recall = TN / (TN + FP)\n",
    "\n",
    "    print(f\"Positive Class: {positive_class}\")\n",
    "    print(f\"Negative Class: {negative_class}\")\n",
    "    print()\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Positive Precision: {positive_precision:.4f}\")\n",
    "    print(f\"Positive Recall: {positive_recall:.4f}\")\n",
    "    print(f\"Negative Precision: {negative_precision:.4f}\")\n",
    "    print(f\"Negative Recall: {negative_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f0eda82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P' 'P' 'N' 'N' 'P' 'N' 'N' 'N' 'P' 'N' 'N' 'N' 'N' 'P' 'P' 'N' 'N' 'N'\n",
      " 'N' 'N']\n",
      "['N', 'P', 'N', 'P', 'P', 'N', 'P', 'N', 'P', 'N', 'N', 'N', 'P', 'P', 'P', 'N', 'N', 'N', 'P', 'N']\n",
      "5\n",
      "4\n",
      "Positive Class: P\n",
      "Negative Class: N\n",
      "\n",
      "Accuracy: 0.7500\n",
      "Positive Precision: 0.5556\n",
      "Positive Recall: 0.8333\n",
      "Negative Precision: 0.9091\n",
      "Negative Recall: 0.7143\n"
     ]
    }
   ],
   "source": [
    "classification_report(true_diag, pred_diag)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
